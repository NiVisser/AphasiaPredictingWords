{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHqWCtUOKgSc",
    "outputId": "e96888ad-d3a2-4233-c392-a81abd644e67"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece datasets"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, TFRobertaForMaskedLM"
   ],
   "metadata": {
    "id": "0suWlkjqKlI8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "RANDOM_SEED = 1337\n",
    "\n",
    "transformers.set_seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ],
   "metadata": {
    "id": "STejj9H8KlLI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAtyFDSZKlNP",
    "outputId": "b05c81e5-43ff-4cb7-cd06-640c63380acb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def count_mask(input_sentences):\n",
    "    mask_count = []\n",
    "    for sentence in input_sentences:\n",
    "        mask_count.append(sentence.count('[MASK]'))\n",
    "    return mask_count"
   ],
   "metadata": {
    "id": "_d6rscoA8K83"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Select scenario to use for prediction\n",
    "scenario_mode = ['narration_mode', 'picture_description','open_ended']\n",
    "scenario_mode = scenario_mode[0]"
   ],
   "metadata": {
    "id": "tpi48Wh5YEOj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if scenario_mode == 'narration_mode' or scenario_mode == 'picture_description':\n",
    "  df = pd.read_csv(\"protocol_aphasia_cosine.csv\", index_col=0)\n",
    "  df = df.loc[(df['similar_sentence_score'] < 1)]\n",
    "  df = df.loc[(df['similar_sentence_score'] > 0.500)]\n",
    "else:\n",
    "  df = pd.read_csv(\"protocol_aphasia_anomic_preprocessed.csv\", index_col=0)"
   ],
   "metadata": {
    "id": "QCiWP3qQ5SNy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if scenario_mode == 'narration_mode':\n",
    "  # Using trained model on Narration scenario:\n",
    "  selected_scenario = [\"Cinderella\", \"Sandwich\"]\n",
    "  MODEL_NAME = \"Middelz2/roberta-large-aphasia-narration-10e\"\n",
    "  MODEL_MODE = \"narration\"\n",
    "  df = df.loc[df['scenario'].isin(selected_scenario)]\n",
    "elif scenario_mode == 'picture_description':\n",
    "  # Using trained model on Picture description scenario:\n",
    "  selected_scenario = [\"Window\", \"Cat\", \"Umbrella\", \"Flood\"]\n",
    "  MODEL_NAME = \"Middelz2/roberta-large-aphasia-picture-description-10e\"\n",
    "  MODEL_MODE = \"picture_description\"\n",
    "  df = df.loc[df['scenario'].isin(selected_scenario)]\n",
    "else:\n",
    "  # Using standard (non-pretrained model) on open ended scenario:\n",
    "  selected_scenario = [\"Important_Event\", \"Speech\", \"Stroke\"]\n",
    "  MODEL_NAME = \"roberta-large\"\n",
    "  MODEL_MODE = \"open_ended\"\n",
    "  df = df.loc[df['scenario'].isin(selected_scenario)]\n",
    "\n",
    "\n",
    "# selected_scenario = [\"Cinderella\", \"Sandwich\"]\n",
    "# MODEL_NAME = \"roberta-large\"\n",
    "# MODEL_MODE = \"picture_description\"\n",
    "# df = df.loc[df['scenario'].isin(selected_scenario)]"
   ],
   "metadata": {
    "id": "T7vB-cEDTUVj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_single_mask_df_cosine(input_dataframe):\n",
    "  \"\"\"\n",
    "  Converts sentences into sentences containing only 1 single mask.\n",
    "  Only used for picture description and narration.\n",
    "  \"\"\"\n",
    "  df = input_dataframe\n",
    "\n",
    "  output_df = pd.DataFrame()\n",
    "  original_sentences = []\n",
    "  scenario = []\n",
    "  sentence_variations = []  # The list that contains all sentences containing a single [MASK]\n",
    "  similar_sentences = []\n",
    "  similarity_score = []\n",
    "  for i in range(0, len(df) - 1):\n",
    "      mask_sentence = df['preprocessed_text'].iloc[i]\n",
    "      words = mask_sentence.split(\" \")\n",
    "      mask_locations = list(np.where(np.array(words) == '[MASK]')[0])\n",
    "      mask_count = len(mask_locations)\n",
    "\n",
    "      for j in range(0, mask_count):\n",
    "          current_mask_count = 0\n",
    "          word_variations = []\n",
    "          for word in words:\n",
    "              if word == '[MASK]':\n",
    "                  if current_mask_count == j:\n",
    "                      word_variations.append(word)\n",
    "                  current_mask_count += 1\n",
    "              else:\n",
    "                  word_variations.append(word)\n",
    "\n",
    "          scenario.append(df['scenario'].iloc[i])\n",
    "          original_sentences.append(df['preprocessed_text'].iloc[i])\n",
    "          sentence_variations.append(\" \".join(word_variations))\n",
    "          similar_sentences.append(df['similar_sentences'].iloc[i])\n",
    "          similarity_score.append(df['similar_sentence_score'].iloc[i])\n",
    "\n",
    "  output_df['scenario'] = scenario\n",
    "  output_df['original_sentences'] = original_sentences\n",
    "  output_df['sentence_variations'] = sentence_variations\n",
    "  output_df['similar_sentences'] = similar_sentences\n",
    "  output_df['similar_sentence_score'] = similarity_score\n",
    "\n",
    "  return output_df\n"
   ],
   "metadata": {
    "id": "x2C6ZvA9ecPQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_single_mask_df_open_ended(input_dataframe):\n",
    "  \"\"\"\n",
    "  Converts sentences into sentences containing only 1 single mask.\n",
    "  Only used for open ended questions.\n",
    "  \"\"\"\n",
    "  df = input_dataframe\n",
    "\n",
    "  output_df = pd.DataFrame()\n",
    "  original_sentences = []\n",
    "  scenario = []\n",
    "  sentence_variations = []  # The list that contains all sentences containing a single [MASK]\n",
    "  for i in range(0, len(df) - 1):\n",
    "      mask_sentence = df['preprocessed_text'].iloc[i]\n",
    "      words = mask_sentence.split(\" \")\n",
    "      mask_locations = list(np.where(np.array(words) == '[MASK]')[0])\n",
    "      mask_count = len(mask_locations)\n",
    "\n",
    "      for j in range(0, mask_count):\n",
    "          current_mask_count = 0\n",
    "          word_variations = []\n",
    "          for word in words:\n",
    "              if word == '[MASK]':\n",
    "                  if current_mask_count == j:\n",
    "                      word_variations.append(word)\n",
    "                  current_mask_count += 1\n",
    "              else:\n",
    "                  word_variations.append(word)\n",
    "\n",
    "          scenario.append(df['scenario'].iloc[i])\n",
    "          original_sentences.append(df['preprocessed_text'].iloc[i])\n",
    "          sentence_variations.append(\" \".join(word_variations))\n",
    "\n",
    "  output_df['scenario'] = scenario\n",
    "  output_df['original_sentences'] = original_sentences\n",
    "  output_df['sentence_variations'] = sentence_variations\n",
    "\n",
    "  return output_df"
   ],
   "metadata": {
    "id": "ywP9BHuTZxoM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if scenario_mode == 'narration_mode' or scenario_mode == 'picture_description':\n",
    "  df = make_single_mask_df_cosine(df)\n",
    "else:\n",
    "  df = make_single_mask_df_open_ended(df)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "id": "IbUibTTEchht",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "outputId": "018c78e8-a07e-4c0a-c2fd-086ad992dbe2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     scenario                                 original_sentences  \\\n",
       "0  Cinderella  well [MASK] Cinderella she had [MASK] a stepmo...   \n",
       "1  Cinderella  well [MASK] Cinderella she had [MASK] a stepmo...   \n",
       "2  Cinderella  well [MASK] Cinderella she had [MASK] a stepmo...   \n",
       "3  Cinderella  and [MASK] and a fairy godmother comes appears...   \n",
       "4  Cinderella            and [MASK] all of the mean mad mouses .   \n",
       "\n",
       "                                 sentence_variations  \\\n",
       "0  well [MASK] Cinderella she had a stepmother an...   \n",
       "1  well Cinderella she had [MASK] a stepmother an...   \n",
       "2  well Cinderella she had a stepmother and two [...   \n",
       "3  and [MASK] and a fairy godmother comes appears...   \n",
       "4            and [MASK] all of the mean mad mouses .   \n",
       "\n",
       "                           similar_sentences  similar_sentence_score  \n",
       "0       Cinderella was had two stepsisters .                0.843088  \n",
       "1       Cinderella was had two stepsisters .                0.843088  \n",
       "2       Cinderella was had two stepsisters .                0.843088  \n",
       "3   and her fairy godmother appears to her .                0.805084  \n",
       "4  and the four mice they are just sitting .                0.599064  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-c0ec3091-86ea-494f-bf9f-597087820490\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>original_sentences</th>\n",
       "      <th>sentence_variations</th>\n",
       "      <th>similar_sentences</th>\n",
       "      <th>similar_sentence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>well [MASK] Cinderella she had [MASK] a stepmo...</td>\n",
       "      <td>well [MASK] Cinderella she had a stepmother an...</td>\n",
       "      <td>Cinderella was had two stepsisters .</td>\n",
       "      <td>0.843088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>well [MASK] Cinderella she had [MASK] a stepmo...</td>\n",
       "      <td>well Cinderella she had [MASK] a stepmother an...</td>\n",
       "      <td>Cinderella was had two stepsisters .</td>\n",
       "      <td>0.843088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>well [MASK] Cinderella she had [MASK] a stepmo...</td>\n",
       "      <td>well Cinderella she had a stepmother and two [...</td>\n",
       "      <td>Cinderella was had two stepsisters .</td>\n",
       "      <td>0.843088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>and [MASK] and a fairy godmother comes appears...</td>\n",
       "      <td>and [MASK] and a fairy godmother comes appears...</td>\n",
       "      <td>and her fairy godmother appears to her .</td>\n",
       "      <td>0.805084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>and [MASK] all of the mean mad mouses .</td>\n",
       "      <td>and [MASK] all of the mean mad mouses .</td>\n",
       "      <td>and the four mice they are just sitting .</td>\n",
       "      <td>0.599064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0ec3091-86ea-494f-bf9f-597087820490')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c0ec3091-86ea-494f-bf9f-597087820490 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c0ec3091-86ea-494f-bf9f-597087820490');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if scenario_mode == 'narration_mode' or scenario_mode == 'picture_description':\n",
    "  df['word_count'] = df['sentence_variations'].str.split().str.len()\n",
    "  df = df.loc[(df['word_count'] > 2)]\n",
    "  df['sentence_variations'] = df['sentence_variations'].apply(lambda x: x.replace(\"[MASK]\", \"<mask>\"))\n",
    "  df['combined_sentences_w_sep'] = df['similar_sentences'] + \" </s> \" +  df['sentence_variations']\n",
    "\n",
    "  df.head()\n",
    "else:\n",
    "  df['word_count'] = df['sentence_variations'].str.split().str.len()\n",
    "  df = df.loc[(df['word_count'] > 2)]\n",
    "  df['sentence_variations'] = df['sentence_variations'].apply(lambda x: x.replace(\"[MASK]\", \"<mask>\"))\n",
    "  df.head()\n"
   ],
   "metadata": {
    "id": "tI4JXyEbevRM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, TFBertModel, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = TFRobertaForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "predicted_words = [[],[],[],[],[]]\n",
    "predicted_scores = [[],[],[],[],[]]\n",
    "\n",
    "model = pipeline('fill-mask', model=MODEL_NAME, device=0)\n",
    "\n",
    "if scenario_mode == 'narration_mode' or scenario_mode == 'picture_description':\n",
    "  predictions = model(df['combined_sentences_w_sep'].to_list(), top_k=5)\n",
    "else:\n",
    "  predictions = model(df['sentence_variations'].to_list(), top_k=5)\n",
    "\n",
    "\n",
    "for prediction in predictions:\n",
    "  for i in range(0, 5):\n",
    "    try:\n",
    "      predicted_words[i].append(prediction[i]['token_str'])\n",
    "    except:\n",
    "      predicted_words[i].append('')\n",
    "    try:\n",
    "      predicted_scores[i].append(prediction[i]['score'])\n",
    "    except:\n",
    "      predicted_scores[i].append(0.0)"
   ],
   "metadata": {
    "id": "hLuT9PdlLR4Y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ea83f175-6ef3-4582-b89e-29f4c14981cd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['word_pred_0'] = predicted_words[0]\n",
    "df['score_pred_0'] = predicted_scores[0]\n",
    "df['word_pred_1'] = predicted_words[1]\n",
    "df['score_pred_1'] = predicted_scores[1]\n",
    "df['word_pred_2'] = predicted_words[2]\n",
    "df['score_pred_2'] = predicted_scores[2]\n",
    "df['word_pred_3'] = predicted_words[3]\n",
    "df['score_pred_3'] = predicted_scores[3]\n",
    "df['word_pred_4'] = predicted_words[4]\n",
    "df['score_pred_4'] = predicted_scores[4]"
   ],
   "metadata": {
    "id": "LrW-ODJAAnG2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_csv(\"maskandsep_preds_\" + MODEL_MODE + \"_non_pretrained\" +  \".csv\")"
   ],
   "metadata": {
    "id": "RrqyTeOGBOV7"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
